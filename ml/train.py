"""
2D â†’ 3D Pose ë³€í™˜ ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (ì „ì²´ ë°ì´í„°ìš©)
- 189ë§Œ ê°œ ë°ì´í„° í•™ìŠµ
- GPU ê°€ì† ì§€ì›
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
from tqdm import tqdm
import time

# ============================================================
# ì„¤ì •
# ============================================================

# ê²½ë¡œ
DATA_PATH = Path(__file__).parent / "processed" / "processed_data.npz"
MODEL_DIR = Path(__file__).parent / "models"

# ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
INPUT_DIM = 48      # 24 joints Ã— 2 (x, y)
OUTPUT_DIM = 72     # 24 joints Ã— 3 (x, y, z)
HIDDEN_DIM = 512    # ë” í° ëª¨ë¸ (ë°ì´í„°ê°€ ë§ìœ¼ë‹ˆê¹Œ)
NUM_BLOCKS = 4      # ë ˆì´ì–´ ìˆ˜ ì¦ê°€

# í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°
BATCH_SIZE = 1024   # í° ë°°ì¹˜ (GPU ë©”ëª¨ë¦¬ í™œìš©)
LEARNING_RATE = 0.001
EPOCHS = 50         # ë°ì´í„°ê°€ ë§ì•„ì„œ 50 ì—í¬í¬ë¡œ ì¶©ë¶„
WEIGHT_DECAY = 1e-4

# ë””ë°”ì´ìŠ¤
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# ============================================================
# ëª¨ë¸ ì •ì˜
# ============================================================

class ResidualBlock(nn.Module):
    """ì”ì°¨ ë¸”ë¡"""
    def __init__(self, dim):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(dim, dim),
            nn.BatchNorm1d(dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(dim, dim),
            nn.BatchNorm1d(dim),
        )
        self.relu = nn.ReLU()
    
    def forward(self, x):
        return self.relu(x + self.layers(x))


class Pose2Dto3DModel(nn.Module):
    """2D â†’ 3D í¬ì¦ˆ ë³€í™˜ ëª¨ë¸"""
    def __init__(self, input_dim=INPUT_DIM, output_dim=OUTPUT_DIM, 
                 hidden_dim=HIDDEN_DIM, num_blocks=NUM_BLOCKS):
        super().__init__()
        
        # ì…ë ¥ ë ˆì´ì–´
        self.input_layer = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
        )
        
        # ì”ì°¨ ë¸”ë¡ë“¤
        self.res_blocks = nn.Sequential(
            *[ResidualBlock(hidden_dim) for _ in range(num_blocks)]
        )
        
        # ì¶œë ¥ ë ˆì´ì–´
        self.output_layer = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, x):
        x = self.input_layer(x)
        x = self.res_blocks(x)
        x = self.output_layer(x)
        return x


# ============================================================
# ì†ì‹¤ í•¨ìˆ˜
# ============================================================

def mpjpe_loss(pred, target):
    """Mean Per Joint Position Error (MPJPE)"""
    # (batch, 72) â†’ (batch, 24, 3)
    pred = pred.view(-1, 24, 3)
    target = target.view(-1, 24, 3)
    
    # ê° ê´€ì ˆë³„ ìœ í´ë¦¬ë“œ ê±°ë¦¬ì˜ í‰ê· 
    return torch.mean(torch.sqrt(torch.sum((pred - target) ** 2, dim=2)))


# ============================================================
# í•™ìŠµ í•¨ìˆ˜
# ============================================================

def train_model():
    print("=" * 60)
    print("2D â†’ 3D Pose ë³€í™˜ ëª¨ë¸ í•™ìŠµ (ì „ì²´ ë°ì´í„°)")
    print("=" * 60)
    
    # ë°ì´í„° ë¡œë“œ
    print(f"\nğŸ“‚ ë°ì´í„° ë¡œë“œ: {DATA_PATH}")
    data = np.load(DATA_PATH)
    
    # ìƒˆë¡œìš´ í‚¤ ì´ë¦„ ì‚¬ìš©
    X_train = torch.FloatTensor(data['train_2d'])
    y_train = torch.FloatTensor(data['train_3d'])
    X_val = torch.FloatTensor(data['val_2d'])
    y_val = torch.FloatTensor(data['val_3d'])
    
    print(f"   - í•™ìŠµ ë°ì´í„°: {len(X_train):,}ê°œ")
    print(f"   - ê²€ì¦ ë°ì´í„°: {len(X_val):,}ê°œ")
    
    # ë°ì´í„°ë¡œë”
    train_dataset = TensorDataset(X_train, y_train)
    val_dataset = TensorDataset(X_val, y_val)
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=True,
        num_workers=0,
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=BATCH_SIZE,
        num_workers=0,
        pin_memory=True
    )
    
    # ëª¨ë¸ ìƒì„±
    print(f"\nğŸ”§ ëª¨ë¸ ìƒì„±")
    model = Pose2Dto3DModel().to(DEVICE)
    print(f"   - ë””ë°”ì´ìŠ¤: {DEVICE}")
    print(f"   - íˆë“  ì°¨ì›: {HIDDEN_DIM}")
    print(f"   - ë ˆì´ì–´ ìˆ˜: {NUM_BLOCKS}")
    print(f"   - íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}ê°œ")
    
    # ì˜µí‹°ë§ˆì´ì € & ìŠ¤ì¼€ì¤„ëŸ¬
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)
    
    # ì†ì‹¤ í•¨ìˆ˜
    mse_loss = nn.MSELoss()
    
    # í•™ìŠµ ê¸°ë¡
    history = {
        'train_loss': [], 'val_loss': [],
        'train_mpjpe': [], 'val_mpjpe': []
    }
    
    best_val_loss = float('inf')
    MODEL_DIR.mkdir(parents=True, exist_ok=True)
    
    # í•™ìŠµ ì‹œì‘
    print(f"\nğŸš€ í•™ìŠµ ì‹œì‘ (Epochs: {EPOCHS}, Batch: {BATCH_SIZE})")
    print("-" * 60)
    
    start_time = time.time()
    
    for epoch in range(EPOCHS):
        # Training
        model.train()
        train_losses = []
        train_mpjpes = []
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1:3d}/{EPOCHS}", leave=False)
        for X_batch, y_batch in pbar:
            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)
            
            optimizer.zero_grad()
            pred = model(X_batch)
            
            loss = mse_loss(pred, y_batch)
            mpjpe = mpjpe_loss(pred, y_batch)
            
            loss.backward()
            optimizer.step()
            
            train_losses.append(loss.item())
            train_mpjpes.append(mpjpe.item())
            
            pbar.set_postfix({'loss': f'{loss.item():.4f}'})
        
        # Validation
        model.eval()
        val_losses = []
        val_mpjpes = []
        
        with torch.no_grad():
            for X_batch, y_batch in val_loader:
                X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)
                pred = model(X_batch)
                
                loss = mse_loss(pred, y_batch)
                mpjpe = mpjpe_loss(pred, y_batch)
                
                val_losses.append(loss.item())
                val_mpjpes.append(mpjpe.item())
        
        # ì—í¬í¬ í‰ê· 
        train_loss = np.mean(train_losses)
        val_loss = np.mean(val_losses)
        train_mpjpe = np.mean(train_mpjpes)
        val_mpjpe = np.mean(val_mpjpes)
        
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['train_mpjpe'].append(train_mpjpe)
        history['val_mpjpe'].append(val_mpjpe)
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
        scheduler.step()
        
        # ì¶œë ¥
        print(f"Epoch [{epoch+1:3d}/{EPOCHS}] | "
              f"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | "
              f"Train MPJPE: {train_mpjpe:.4f} | Val MPJPE: {val_mpjpe:.4f}")
        
        # ìµœê³  ëª¨ë¸ ì €ì¥
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': val_loss,
                'val_mpjpe': val_mpjpe,
            }, MODEL_DIR / "best_model.pth")
    
    # í•™ìŠµ ì™„ë£Œ
    elapsed_time = time.time() - start_time
    print("-" * 60)
    print(f"\nâœ… í•™ìŠµ ì™„ë£Œ!")
    print(f"   - ì†Œìš” ì‹œê°„: {elapsed_time/60:.1f}ë¶„")
    print(f"   - ìµœê³  ê²€ì¦ ì†ì‹¤: {best_val_loss:.6f}")
    print(f"   - ëª¨ë¸ ì €ì¥: {MODEL_DIR / 'best_model.pth'}")
    
    # ìµœì¢… ëª¨ë¸ ì €ì¥
    torch.save({
        'epoch': EPOCHS,
        'model_state_dict': model.state_dict(),
        'val_loss': val_loss,
    }, MODEL_DIR / "final_model.pth")
    
    # í•™ìŠµ ê³¡ì„  ì €ì¥
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))
    
    axes[0].plot(history['train_loss'], label='Train')
    axes[0].plot(history['val_loss'], label='Validation')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].set_title('Loss Curve')
    axes[0].legend()
    axes[0].grid(True)
    
    axes[1].plot(history['train_mpjpe'], label='Train')
    axes[1].plot(history['val_mpjpe'], label='Validation')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('MPJPE')
    axes[1].set_title('MPJPE Curve')
    axes[1].legend()
    axes[1].grid(True)
    
    plt.tight_layout()
    plt.savefig(MODEL_DIR / "training_history.png", dpi=150)
    print(f"   - í•™ìŠµ ê³¡ì„ : {MODEL_DIR / 'training_history.png'}")


if __name__ == "__main__":
    train_model()
