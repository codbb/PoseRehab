"""
PyTorch â†’ ONNX ëª¨ë¸ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ (ì „ì²´ ë°ì´í„°ìš©)
- train.pyì˜ ëª¨ë¸ êµ¬ì¡°ì™€ ë™ì¼í•´ì•¼ í•¨
"""

import torch
import torch.nn as nn
import numpy as np
from pathlib import Path
import json
import onnx
import onnxruntime as ort

# ============================================================
# ì„¤ì • (train.pyì™€ ë™ì¼í•˜ê²Œ!)
# ============================================================

INPUT_DIM = 48
OUTPUT_DIM = 72
HIDDEN_DIM = 512
NUM_BLOCKS = 4

MODEL_DIR = Path(__file__).parent / "models"
OUTPUT_DIR = Path(__file__).parent.parent / "public" / "models"


# ============================================================
# ëª¨ë¸ ì •ì˜ (train.pyì™€ ë™ì¼!)
# ============================================================

class ResidualBlock(nn.Module):
    """ì”ì°¨ ë¸”ë¡"""
    def __init__(self, dim):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(dim, dim),
            nn.BatchNorm1d(dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(dim, dim),
            nn.BatchNorm1d(dim),
        )
        self.relu = nn.ReLU()
    
    def forward(self, x):
        return self.relu(x + self.layers(x))


class Pose2Dto3DModel(nn.Module):
    """2D â†’ 3D í¬ì¦ˆ ë³€í™˜ ëª¨ë¸"""
    def __init__(self, input_dim=INPUT_DIM, output_dim=OUTPUT_DIM, 
                 hidden_dim=HIDDEN_DIM, num_blocks=NUM_BLOCKS):
        super().__init__()
        
        # ì…ë ¥ ë ˆì´ì–´
        self.input_layer = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
        )
        
        # ì”ì°¨ ë¸”ë¡ë“¤
        self.res_blocks = nn.Sequential(
            *[ResidualBlock(hidden_dim) for _ in range(num_blocks)]
        )
        
        # ì¶œë ¥ ë ˆì´ì–´
        self.output_layer = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, x):
        x = self.input_layer(x)
        x = self.res_blocks(x)
        x = self.output_layer(x)
        return x


# ============================================================
# ONNX ë³€í™˜
# ============================================================

def export_to_onnx():
    print("=" * 60)
    print("PyTorch â†’ ONNX ëª¨ë¸ ë³€í™˜")
    print("=" * 60)
    
    # ëª¨ë¸ ê²½ë¡œ
    model_path = MODEL_DIR / "best_model.pth"
    
    if not model_path.exists():
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return
    
    # ëª¨ë¸ ë¡œë“œ
    print(f"\nğŸ“‚ ëª¨ë¸ ë¡œë“œ: {model_path}")
    checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
    
    print(f"   - ì²´í¬í¬ì¸íŠ¸ ì—í¬í¬: {checkpoint.get('epoch', 'N/A')}")
    print(f"   - ê²€ì¦ ì†ì‹¤: {checkpoint.get('val_loss', 'N/A'):.6f}")
    print(f"   - ê²€ì¦ MPJPE: {checkpoint.get('val_mpjpe', 'N/A'):.4f}")
    
    # ëª¨ë¸ ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
    model = Pose2Dto3DModel()
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    # ONNX ë³€í™˜
    print(f"\nğŸ”„ ONNX ë³€í™˜ ì¤‘...")
    
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    onnx_path = OUTPUT_DIR / "pose2d_to_3d.onnx"
    
    # ë”ë¯¸ ì…ë ¥
    dummy_input = torch.randn(1, INPUT_DIM)
    
    # ë³€í™˜
    torch.onnx.export(
        model,
        dummy_input,
        onnx_path,
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=['input_2d'],
        output_names=['output_3d'],
        dynamic_axes={
            'input_2d': {0: 'batch_size'},
            'output_3d': {0: 'batch_size'}
        }
    )
    
    file_size = onnx_path.stat().st_size / 1024
    print(f"   âœ… ì €ì¥ ì™„ë£Œ: {onnx_path}")
    print(f"   - íŒŒì¼ í¬ê¸°: {file_size:.1f} KB")
    
    # ONNX ê²€ì¦
    print(f"\nğŸ” ONNX ëª¨ë¸ ê²€ì¦...")
    onnx_model = onnx.load(onnx_path)
    onnx.checker.check_model(onnx_model)
    print(f"   âœ… ëª¨ë¸ ê²€ì¦ í†µê³¼!")
    
    # ONNX Runtime í…ŒìŠ¤íŠ¸
    print(f"\nğŸ§ª ONNX Runtime ì¶”ë¡  í…ŒìŠ¤íŠ¸...")
    ort_session = ort.InferenceSession(str(onnx_path))
    
    test_input = np.random.randn(1, INPUT_DIM).astype(np.float32)
    outputs = ort_session.run(None, {'input_2d': test_input})
    
    print(f"   - ì…ë ¥ í˜•íƒœ: {test_input.shape}")
    print(f"   - ì¶œë ¥ í˜•íƒœ: {outputs[0].shape}")
    print(f"   âœ… ì¶”ë¡  í…ŒìŠ¤íŠ¸ í†µê³¼!")
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        "input_dim": INPUT_DIM,
        "output_dim": OUTPUT_DIM,
        "hidden_dim": HIDDEN_DIM,
        "num_blocks": NUM_BLOCKS,
        "num_joints": 24,
        "joint_names": [
            "Pelvis", "L_Hip", "R_Hip", "Spine1", "L_Knee", "R_Knee",
            "Spine2", "L_Ankle", "R_Ankle", "Spine3", "L_Foot", "R_Foot",
            "Neck", "L_Collar", "R_Collar", "Head", "L_Shoulder", "R_Shoulder",
            "L_Elbow", "R_Elbow", "L_Wrist", "R_Wrist", "L_Hand", "R_Hand"
        ],
        "training_info": {
            "epoch": checkpoint.get('epoch', 'N/A'),
            "val_loss": float(checkpoint.get('val_loss', 0)),
            "val_mpjpe": float(checkpoint.get('val_mpjpe', 0)),
            "train_samples": 1779527,
            "val_samples": 114514
        },
        "normalization": {
            "img_width": 1920,
            "img_height": 1080,
            "pose_3d_scale": 1000.0
        }
    }
    
    metadata_path = OUTPUT_DIR / "pose2d_to_3d_metadata.json"
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"   - ë©”íƒ€ë°ì´í„°: {metadata_path}")
    
    print(f"\n{'='*60}")
    print("âœ… ONNX ë³€í™˜ ì™„ë£Œ!")
    print(f"{'='*60}")
    print(f"\nğŸ“ Next.jsì—ì„œ ì‚¬ìš©í•  íŒŒì¼:")
    print(f"   - {onnx_path}")
    print(f"   - {metadata_path}")


if __name__ == "__main__":
    export_to_onnx()
